{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fece46d-f10f-4866-8806-3b70ba3d4c39",
   "metadata": {},
   "source": [
    "## Notebook 03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b1b10-13ff-4d4e-9e1f-497c7e30ca47",
   "metadata": {},
   "source": [
    "### Passos\n",
    "O primeiro passo é a importação dos pacotes necessários para a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f443fd42-4b75-4466-983e-0432455dbbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# load custom modules\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "from pilotoeducacao.queries import put_results\n",
    "\n",
    "# definir root como path\n",
    "ROOT = Path().resolve().parent\n",
    "DATA = ROOT / 'data' / 'rodada01'\n",
    "\n",
    "rodada = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf85ed-8f2e-467e-82a5-930cf7845abb",
   "metadata": {},
   "source": [
    "### Importar dados\n",
    "Depois, nós devemos importar os resultados da busca para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca6c95-4410-42d4-92e6-cad6e4217039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir lista de resultados\n",
    "resultados = []\n",
    "arquivos = DATA.iterdir()\n",
    "arquivos = sorted(list(arquivos))\n",
    "arquivos = [arquivo for arquivo in arquivos if not re.search(r'csv', str(arquivo))]\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    with open(arquivo, 'rb') as handle:\n",
    "        resultado = pickle.load(handle)\n",
    "        resultados.append(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb25e299-84c1-44ab-8b1b-40a580282fcf",
   "metadata": {},
   "source": [
    "### Análise Quantitativa\n",
    "Primeiro nós demonstramos quantos resultados obtivémos usando os termos de busca definidos pelo nosso grupo. Na primeira busca, limitamos os resultados a 10.000 ocorrências para testarmos a qualidade do mecanismo de ranqueamento dos documentos do nosso servidor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20976be1-f47a-4812-97ae-4816dd30aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "termos = ['compras', 'educação', 'tecnologia']\n",
    "dados = {\n",
    "    'Exercício': ['Factual'] * 3 + ['Contrafactual'] * 3,\n",
    "    'Termo': termos + termos[::-1], \n",
    "    'Hits': [r['hits']['value'] for r in resultados]\n",
    "}\n",
    "df = pd.DataFrame(data=dados)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc616ec4-fe80-44dd-9ddf-8a44aae24841",
   "metadata": {},
   "source": [
    "### Cálculo de Matriz de Confusão\n",
    "Para nosso cálculo de matriz de confusão, nós precisamos comparar os hits do exerício factual contra os hits do exercício contrafactual. Precisamos definir quatro grupos:\n",
    "1. **G1 Factual Positivos:** grupo identificado pela busca sequencial compras >> educação >> tecnologia.\n",
    "2. **G2 Factual Negativos:** grupo excluído pela busca sequencial compras >> educação >> tecnologia.\n",
    "3. **G3 Contrafactual Positivos:** grupo identificado pela busca sequencial tecnologia >> educação >> compras.\n",
    "4. **G4 Contrafactual Negativos:** grupo excluído pela busca sequencial tecnologia >> educação >> compras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e7a1a-acc2-4cf1-9d80-44e37696a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular os grupos\n",
    "G1 = set(resultados[2]['ids'])\n",
    "G2 = set(resultados[0]['ids']) - set(resultados[2]['ids'])\n",
    "         \n",
    "G3 = set(resultados[5]['ids'])\n",
    "G4 = set(resultados[3]['ids']) - set(resultados[5]['ids'])\n",
    "\n",
    "# definir grupos\n",
    "true_positive = len(G1 & G3)\n",
    "true_negative = len(G2 & G4)\n",
    "false_positive = len(G1 - (G1 & G3))\n",
    "false_negative = len(G2 - (G2 & G4))\n",
    "\n",
    "print(f'Matriz de Confusão')\n",
    "print(f'---------------------------')\n",
    "print(f'True Positives (TP):  {true_positive:05d}')\n",
    "print(f'True Negatives (TN):  {true_negative:05d}')\n",
    "print(f'False Positives (FP): {false_positive:05d}')\n",
    "print(f'False Negatives (FN): {false_negative:05d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddacaf2a-ae12-4537-9660-a3dc5c49befb",
   "metadata": {},
   "source": [
    "##### Subir os Resultados na Planilha do Google\n",
    "Finalmente, nós subimos os resultados para que tenhamos um registro das buscas de fácil acesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c456ea1-74ee-4022-a59b-583c9e797a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_creds = str(ROOT / 'tests/data/YOUR_CREDENTIALS.json')\n",
    "\n",
    "# HITS\n",
    "# range da planilha a substituir\n",
    "range_ = f'queries!F{3*rodada-1}:J30'\n",
    "\n",
    "# definir corpo dos valores a subir\n",
    "value_range_body = {\n",
    "    \"majorDimension\": \"COLUMNS\",\n",
    "    'values': [\n",
    "        [r['hits']['value'] for r in resultados[:3]], \n",
    "    ]\n",
    "}\n",
    "\n",
    "# imprimir resultados\n",
    "put_results(google_creds, range_, value_range_body)\n",
    "\n",
    "# MATRIZ DE CONFUSÃO\n",
    "# range da planilha a substituir\n",
    "range_ = f'resultados!B{1+rodada}:G2'\n",
    "\n",
    "# definir corpo dos valores a subir\n",
    "value_range_body = {\n",
    "    \"majorDimension\": \"ROWS\",\n",
    "    'values': [\n",
    "        [\n",
    "            true_positive,\n",
    "            true_negative,\n",
    "            false_positive,\n",
    "            false_negative,\n",
    "            round(true_positive/(true_positive+false_positive), 2),\n",
    "            round(true_positive/(true_positive+false_negative), 2)\n",
    "        ], \n",
    "    ]\n",
    "}\n",
    "\n",
    "# imprimir resultados\n",
    "put_results(google_creds, range_, value_range_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d4a8f-0942-4849-b74c-f2413e4d4a41",
   "metadata": {},
   "source": [
    "### Análise Qualitativa\n",
    "Para a análise qualitativa dos resultados, precisamos olhar para os scores do ES e sortear quais documentos analisar. Queremos, também, saber o tamanho dos documentos que estamos analizando, portanto, recuperamos também o tamanho de cada arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2029ae-ec87-420a-ba30-d12a0dab884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformar resultados em banco de dados\n",
    "dt = pd.json_normalize(resultados[0]['documents'])\n",
    "dt[['sort.score', 'sort.id']] =  pd.DataFrame(dt['sort'].tolist(), index=dt.index)\n",
    "dt.head()\n",
    "\n",
    "# sortear e salvar em csv\n",
    "dt.sample(n=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feedf10-6059-4d7d-9650-5100c8c4b161",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "Para repetirmos as análises, é só rodarmos o script `preparo_notebook.py` repetidamente selecionando o argumento da rodada de análise, e.g.\n",
    "\n",
    "```python\n",
    "python examples/preparo_notebook.py --rodada=2\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
